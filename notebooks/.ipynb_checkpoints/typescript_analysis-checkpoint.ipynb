{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TypeScript Codebase Analysis\n",
    "\n",
    "This notebook demonstrates how to use the `ts-analyzer` module to analyze TypeScript codebases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ts-analyzer module\n",
    "from ts_analyzer import TypeScriptAnalyzer\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Analyzer\n",
    "\n",
    "First, we need to initialize the analyzer with the path to our TypeScript codebase. Make sure to update the path to point to your TypeScript project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() argument 1 must be tree_sitter.Language, not builtin_function_or_method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m CODEBASE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/ralph/projects/spellcast\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize the analyzer\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mTypeScriptAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCODEBASE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Find all TypeScript files in the codebase\u001b[39;00m\n\u001b[1;32m      9\u001b[0m ts_files \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mfind_ts_files()\n",
      "File \u001b[0;32m~/projects/ts-refactor-stats/ts_analyzer/__init__.py:56\u001b[0m, in \u001b[0;36mTypeScriptAnalyzer.__init__\u001b[0;34m(self, codebase_root)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebase_root \u001b[38;5;241m=\u001b[39m Path(codebase_root)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m     55\u001b[0m initialize_ts_parser()\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m \u001b[43mParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTS_LANGUAGE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Cache for parsed files\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parsed_files_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() argument 1 must be tree_sitter.Language, not builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "# Path to your TypeScript codebase\n",
    "# Change this to the path of your TypeScript project\n",
    "CODEBASE_PATH = \"/Users/ralph/projects/spellcast\"\n",
    "\n",
    "# Initialize the analyzer\n",
    "analyzer = TypeScriptAnalyzer(CODEBASE_PATH)\n",
    "\n",
    "# Find all TypeScript files in the codebase\n",
    "ts_files = analyzer.find_ts_files()\n",
    "print(f\"Found {len(ts_files)} TypeScript files\")\n",
    "\n",
    "# Display the first 5 files\n",
    "for file in ts_files[:5]:\n",
    "    print(f\" - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Imports\n",
    "\n",
    "Let's analyze imports in the codebase to understand dependencies between files and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find imports of a specific module or class\n",
    "# Replace 'react' with any module/class you want to find imports for\n",
    "imports = analyzer.find_imports('react')\n",
    "\n",
    "print(f\"Found {len(imports)} files that import 'react'\")\n",
    "\n",
    "# Display a sample of the imports\n",
    "for file_path, file_imports in list(imports.items())[:3]:\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    for imp in file_imports:\n",
    "        print(f\"  Line {imp['line']}: {imp['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Function Calls\n",
    "\n",
    "We can identify where specific functions are being called in the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find calls to a specific function\n",
    "# Replace 'useState' with any function you want to find calls for\n",
    "function_calls = analyzer.find_function_calls('useState', extract_first_arg=True)\n",
    "\n",
    "print(f\"Found {len(function_calls)} files with calls to 'useState'\")\n",
    "\n",
    "# Display a sample of the function calls\n",
    "for file_path, calls in list(function_calls.items())[:3]:\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    for call in calls[:2]:  # Show only the first 2 calls per file\n",
    "        print(f\"  Line {call['line']}: {call['text']}\")\n",
    "        if 'first_arg' in call:\n",
    "            print(f\"    First argument: {call['first_arg']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definitions Analysis\n",
    "\n",
    "Let's analyze class definitions in the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all class definitions\n",
    "classes = analyzer.find_class_definitions()\n",
    "\n",
    "# Count classes per file\n",
    "class_counts = {file_path: len(class_list) for file_path, class_list in classes.items()}\n",
    "\n",
    "# Display total class count\n",
    "total_classes = sum(class_counts.values())\n",
    "print(f\"Found {total_classes} classes across {len(classes)} files\")\n",
    "\n",
    "# Show files with the most classes\n",
    "top_files = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"\\nFiles with the most classes:\")\n",
    "for file_path, count in top_files:\n",
    "    print(f\"  {file_path}: {count} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Codebase Statistics\n",
    "\n",
    "Let's generate comprehensive statistics about the codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate statistics for the codebase\n",
    "stats = analyzer.generate_stats()\n",
    "\n",
    "# Display overview statistics\n",
    "print(f\"Total TypeScript files: {stats['total_files']}\")\n",
    "print(f\"Total lines of code: {stats['total_lines']}\")\n",
    "print(f\"Average lines per file: {stats['avg_lines_per_file']:.2f}\")\n",
    "\n",
    "# Create a DataFrame for the file sizes\n",
    "file_sizes = pd.DataFrame({\n",
    "    'file': [str(Path(file).name) for file in stats['file_sizes'].keys()],\n",
    "    'size': list(stats['file_sizes'].values())\n",
    "})\n",
    "\n",
    "# Plot the distribution of file sizes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(file_sizes['size'], kde=True)\n",
    "plt.title('Distribution of TypeScript File Sizes')\n",
    "plt.xlabel('Lines of Code')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Queries\n",
    "\n",
    "We can use custom TreeSitter queries to find specific patterns in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find all arrow functions\n",
    "query = \"\"\"\n",
    "(arrow_function) @function\n",
    "\"\"\"\n",
    "\n",
    "arrow_functions = analyzer.custom_query(query)\n",
    "\n",
    "print(f\"Found arrow functions in {len(arrow_functions)} files\")\n",
    "\n",
    "# Count arrow functions per file\n",
    "arrow_counts = {file_path: len(matches) for file_path, matches in arrow_functions.items()}\n",
    "total_arrows = sum(arrow_counts.values())\n",
    "print(f\"Total arrow functions found: {total_arrows}\")\n",
    "\n",
    "# Show a sample of arrow functions\n",
    "for file_path, matches in list(arrow_functions.items())[:2]:\n",
    "    print(f\"\\nFile: {file_path}\")\n",
    "    for match in matches[:3]:  # Show only the first 3 matches per file\n",
    "        print(f\"  Line {match['line']}: {match['text'][:50]}...\" if len(match['text']) > 50 else f\"  Line {match['line']}: {match['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Code Patterns\n",
    "\n",
    "Let's create some visualizations to better understand the codebase structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze different kinds of nodes in the code\n",
    "node_types = {\n",
    "    'function_declarations': 0,\n",
    "    'arrow_functions': 0,\n",
    "    'class_declarations': 0,\n",
    "    'interface_declarations': 0,\n",
    "    'type_aliases': 0,\n",
    "    'export_statements': 0,\n",
    "    'import_statements': 0\n",
    "}\n",
    "\n",
    "# Custom queries for each node type\n",
    "queries = {\n",
    "    'function_declarations': \"(function_declaration) @func\",\n",
    "    'arrow_functions': \"(arrow_function) @arrow\",\n",
    "    'class_declarations': \"(class_declaration) @class\",\n",
    "    'interface_declarations': \"(interface_declaration) @interface\",\n",
    "    'type_aliases': \"(type_alias_declaration) @type\",\n",
    "    'export_statements': \"(export_statement) @export\",\n",
    "    'import_statements': \"(import_statement) @import\"\n",
    "}\n",
    "\n",
    "# Run each query and count occurrences\n",
    "for node_type, query in queries.items():\n",
    "    results = analyzer.custom_query(query)\n",
    "    count = sum(len(matches) for matches in results.values())\n",
    "    node_types[node_type] = count\n",
    "    print(f\"Found {count} {node_type}\")\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=list(node_types.keys()), y=list(node_types.values()))\n",
    "plt.title('TypeScript Code Patterns')\n",
    "plt.xlabel('Pattern Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
